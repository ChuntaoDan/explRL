{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agents\n",
    "\n",
    "> This module specifies Policy, RL and Agent Classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Policy:\n",
    "    '''This Policy Class specifies a general architecture. '''\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "        self.actions = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class flexiblePolicy(Policy):\n",
    "    '''This flexiblePolicy Class specifies a fully flexible policy with a set of basis functions and a learnable set of weights. '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.omega = None   # vector of weights\n",
    "        self.fk = None  # basis functions\n",
    "        self.wParams = None # a vector of parameters used to specify nonlinear transformations of the weights\n",
    "        self.integ = None    # an integrator signal used in the drift diffusion process to generate fixations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RL:\n",
    "    '''This RL Class performs reinforcement learning: after taking an action, update parameters \n",
    "    based on feedback from the environment.\n",
    "    '''\n",
    "    def __init__(self,policy):\n",
    "        self.policy = policy\n",
    "        \n",
    "    def chooseAction(self):\n",
    "        pass\n",
    "        return self.act\n",
    "    \n",
    "    def updateParams(self):\n",
    "        pass\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Agent:\n",
    "    '''This Class specifies agents with a defined policy and reinforcement learning algorithm. '''\n",
    "    def __init__(self,theta,goal,policy,rl,params):\n",
    "        self.theta = theta   # current heading\n",
    "        self.goal = goal\n",
    "        self.policy = policy\n",
    "        self.rl = rl\n",
    "        self.params = params  # structure containing simulation parameters\n",
    "        self.dx = None  # change in heading\n",
    "        self.dt = None  # change in time \n",
    "        \n",
    "        \n",
    "    def samplePolicy(self):\n",
    "        raise NotImplementedError(\"Override me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class flexibleAgent(Agent):\n",
    "    '''This Agent Class specifies agents using a fully flexible policy and reinforcement learning algorithm. '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def samplePolicy(self):\n",
    "        '''samples a change in heading over a change in time to use in training'''\n",
    "        \n",
    "        return self.dx, self.dt, self.integ\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
