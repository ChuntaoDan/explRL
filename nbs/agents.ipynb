{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agents\n",
    "\n",
    "> This module specifies the Agent, Policy, and RL Classes. An agent carries one or more policies when exploring an environment, and updates parameters using reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Policy:\n",
    "    '''This Policy Class specifies a general architecture. '''\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "        self.actions = None\n",
    "        self.pi = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class flexiblePolicy(Policy):\n",
    "    '''This flexiblePolicy Class specifies a fully flexible policy with a set of basis functions \n",
    "    and a learnable set of weights. '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.omega = None   # vector of weights\n",
    "        self.fk = None  # basis functions\n",
    "        self.wParams = None # a vector of parameters used to specify nonlinear transformations of the weights\n",
    "        self.integ = None    # an integrator signal used in the drift diffusion process to generate fixations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RL:\n",
    "    '''This RL Class performs reinforcement learning: after taking an action, update parameters \n",
    "    based on feedback from the environment.\n",
    "    '''\n",
    "    def __init__(self,policy):\n",
    "        self.policy = policy\n",
    "        \n",
    "    def chooseAction(self):\n",
    "        pass\n",
    "        return self.act\n",
    "    \n",
    "    def updateParams(self):\n",
    "        pass\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Agent:\n",
    "    '''This Class specifies agents with a defined policy and reinforcement learning algorithm. '''\n",
    "    def __init__(self,theta,goal,policy,rl,params):\n",
    "        self.theta = theta   # current heading\n",
    "        self.goal = goal\n",
    "        self.policy = policy\n",
    "        self.rl = rl\n",
    "        self.params = params  # structure containing simulation parameters\n",
    "        self.dx = None  # change in heading\n",
    "        self.dt = None  # change in time \n",
    "        self.integ = None # an integrator signal used in the drift diffusion process to generate fixations\n",
    "        \n",
    "        \n",
    "    def samplePolicy(self):\n",
    "        raise NotImplementedError(\"Override me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class flexibleAgent(Agent):\n",
    "    '''This Agent Class specifies agents using a fully flexible policy and reinforcement learning algorithm. '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.omega = None # vector of weights\n",
    "        self.fk = None # basis functions       \n",
    "        self.wParams = None # a vector of parameters used to specify nonlinear transformations of the weights\n",
    "\n",
    "    def samplePolicy(self):\n",
    "        '''samples a change in heading over a change in time to use in training'''\n",
    "        \n",
    "        nx       = self.params.nx\n",
    "        thetaVec = np.linspace(0,2*np.pi,num=nx+1)\n",
    "        ind      = np.argmin(np.square(self.theta-thetaVec[:-1]))\n",
    "\n",
    "        # update integrator\n",
    "        nu,pR      = self.convertParams(self.omega,self.fk[:,ind],self.wParams)\n",
    "        self.integ = self.integ + np.random.normal(nu*self.params.delT,self.params.sigF*np.sqrt(self.params.delT))\n",
    "\n",
    "        if self.integ > self.params.aF:\n",
    "            #--------- SACCADE ----------#\n",
    "            if self.flipCoin(pR):\n",
    "                dir = 1\n",
    "            else:\n",
    "                dir = -1\n",
    "    \n",
    "            self.dx = np.multiply(np.multiply(dir,np.random.lognormal(self.params.muS,self.params.sigmaS)),96./360)\n",
    "            self.dt = self.params.dtS\n",
    "            self.integ = 0\n",
    "\n",
    "        else:\n",
    "            #--------- FIXATE ----------#\n",
    "            self.dx = 0\n",
    "            self.dt = 1\n",
    "        \n",
    "        self.dx = round(self.dx)\n",
    "        self.dt = round(self.dt)\n",
    "\n",
    "        return self.dx, self.dt, self.integ\n",
    "        \n",
    "    def convertParams(self):\n",
    "        '''converts a vector of weights into behavioral control parameters (drift rates and turn biases)'''\n",
    "\n",
    "        # See also: GETBASISFUNCTIONS\n",
    "\n",
    "        nb = (np.size(self.omega))/2\n",
    "        omegaF = self.omega[:nb+1].T\n",
    "        omegaR = self.omega[nb+1:].T\n",
    "\n",
    "        nuF = self.sigmoid(omegaF*self.fk,self.wParams[0],self.wParams[1],self.wParams[2])\n",
    "        pR  = self.sigmoid(omegaR*self.fk,self.wParams[3],self.wParams[4],self.wParams[5])\n",
    "\n",
    "        return nuF,pR,omegaF,omegaR\n",
    "    \n",
    "    def sigmoid(self,x,k,fmax,offset):\n",
    "        ''' = FMAX/(1+exp(-K*X))-OFFSET generates a sigmoidal function with slope K, scale FMAX , and vertical shift OFFSET ''' \n",
    "\n",
    "        return np.divide(fmax,(1+np.exp(-k*x))) - offset\n",
    "\n",
    "    def flipCoin(self,p):\n",
    "        # samples from a Bernoulli process with probability P\n",
    "        u = np.random.rand()\n",
    "        if u < p:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
